<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Matt Graham</title>

  <!-- Bootstrap core CSS -->
  <link href="./css/bootstrap.css" rel="stylesheet">

  <!-- FontAwesomeCSS -->
  <link rel="stylesheet" href="./css/font-awesome.min.css">

  <!-- Academicons CSS -->
  <link rel="stylesheet" href="./css/academicons.min.css"/>

  <!-- Custom icons font CSS -->
  <link rel="stylesheet" href="./css/custom-icons.css"/>

  <!-- Bootstrap social css -->
  <link rel="stylesheet" href="./css/bootstrap-social.css">

  <!-- Site specific CSS -->
  <link href="./css/custom.css" rel="stylesheet">

  <!-- MathJax -->
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->

</head>

<body data-spy="scroll" data-target="#mainNav">

  <div class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">Matt Graham</a>
      </div>
      <div class="navbar-collapse collapse">
        <ul class="nav navbar-nav" id="mainNav">
          <li class="active"><a href="#intro">intro</a></li>
          <li><a href="#contact">contact</a></li>
          <li><a href="#publications">publications</a></li>
          <li><a href="#talks">talks</a></li>
          <li><a href="#projects">projects</a></li>
          <li><a href="#code">code</a></li>
          <li><a href="#teaching">teaching</a></li>
          <li><a href="#misc">misc</a></li>
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </div>

  <div class="container">

    <div class="row" id="intro">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Introduction</h1>
        </div>
        <div class="row">
          <div class="col-md-3" id="profile-photo-and-social-col">
            <div class="text-center">
              <img src="images/profile_photo_small.jpg" class="img-thumbnail" width="200" />
            </div>
            <div class="text-center vertical-buffer">
              <div class="btn-group" role="group">
                <a href="https://github.com/matt-graham" class="btn btn-social-icon btn-github">
                  <i class="fa fa-github fa-fw"></i>
                </a>
                <a href="https://uk.linkedin.com/in/matt-graham-460217130" class="btn btn-social-icon btn-linkedin">
                  <i class="fa fa-linkedin fa-fw"></i>
                </a>
                <a href="https://plus.google.com/u/0/+MatthewGrahamUK" class="btn btn-social-icon btn-google-plus">
                  <i class="fa fa-google-plus fa-fw"></i>
                </a>
<!--
                <a href="https://twitter.com/mattgrahamuk" class="btn btn-social-icon btn-twitter">
                  <i class="fa fa-twitter fa-fw"></i>
                </a>
-->
                <a href="https://scholar.google.co.uk/citations?user=1QMZI4kAAAAJ&hl=en" class="btn btn-social-icon btn-google-yellow">
                  <i style="margin-top: 2px;" class="fa icon-google-scholar-g-thicker fa-fw"></i>
                </a>
              </div>
            </div>
          </div> <!--/.profile-photo-and-social-col-->
          <div class="col-md-9" id="intro-text-col">
            <p class="lead">I am a research fellow in the <a href="https://www.stat.nus.edu.sg">Department of Statistics and Applied Probability</a> at the National University of Singapore. I am part of <a href="http://www.normalesup.org/~athiery/index.html">Alex Thiery's</a> research group. My <a href='#publications'>research</a> is focused on developing methods for performing efficient approximate inference in complex probabilistic models.
            </p>
            <p class="lead">
              <span class="text-muted">Research interests:</span> Markov chain Monte Carlo methods, Hamiltonian Monte Carlo, approximate Bayesian computation, numerical simulation.
            </p>
            <div class="btn-group" role="group">
              <span class="btn btn-default active">CV</span>
              <a href="cv.html" class="btn btn-default">
                <i class="fa fa-file-o fa-fw"></i> HTML
              </a>
              <a href="files/cv_matt_graham.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> PDF
              </a>
            </div>
          </div><!--./intro-text-col-->
        </div>
      </div>
    </div><!--./intro-->

    <div class="row" id="contact">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Contact</h1>
        </div>
        <div class="row">
          <div class="col-md-4" id='contact-email-col'>
            <div class="panel panel-default">
              <div class="panel-heading"><i class="fa fa-envelope fa-fw"></i> Email</div>
              <div class="panel-body"><a href="mailto:m[dot]m[dot]graham[at]nus[dot]edu[dot]sg">m&#46;m&#46;graham&#8203;&#64;&#8203;nus&#46;edu&#46;sg</a></div>
            </div><!--./contact-email-col-->
          </div>
          <div class="col-md-8" id="contact-address-col">
            <div class="panel panel-default">
              <div class="panel-heading"><i class="fa fa-building fa-fw"></i> Address</div>
              <div class="panel-body"> Office 05-97, Block S16, 6 Science Drive 2, National University of Singapore, Singapore, 117546 </div>
            </div>
          </div><!--./contact-address-col-->
        </div>
      </div>
    </div><!--./contact-->

    <div class="row" id="publications">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Publications</h1>
        </div>
        <div class="row">
          <h2 class='sub-heading'> Pre-prints </h2>
          <ul class="publications-list">
          <li class="publication">
            <h4>
              Asymptotically exact inference in differentiable generative models
            </h4>
            <p>
              <i>Matthew M. Graham</i> and <a href="http://homepages.inf.ed.ac.uk/amos">Amos J. Storkey</a>
            </p>
            <p class='published-in'>
              <small>To appear in:</small> <a href='http://imstat.org/ejs/'>Electronic Journal of Statistics</a>
            </p>
            <div class="btn-group" role="group">
              <a href="files/dgm-ejs-preprint.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Paper
              </a>
              <a href="slides/dgm" class="btn btn-default">
                <i class="fa fa-television fa-fw"></i> Slides
              </a>
              <a href="https://github.com/matt-graham/differentiable-generative-models" class="btn btn-default">
                <i class="fa fa-code fa-fw"></i> Code
              </a>
              <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#dgm-ejs-abs">
                Abstract
              </button>
            </div>
            <div id="dgm-ejs-abs" class="collapse abstract">
              Many generative models can be expressed as a differentiable function applied to input variables sampled from a known probability distribution. This framework includes both the generative component of learned parametric models such as variational autoencoders and generative adversarial networks, and also procedurally defined simulator models which involve only differentiable operations. Though the distribution on the input variables to such models is known, often the distribution on the output variables is only implicitly defined. We present a method for performing efficient Markov chain Monte Carlo inference in such models when conditioning on observations of the model output. For some models this offers an asymptotically exact inference method where approximate Bayesian computation might otherwise be employed. We use the intuition that computing conditional expectations is equivalent to integrating over a density defined on the manifold corresponding to the set of inputs consistent with the observed outputs. This motivates the use of a constrained variant of Hamiltonian Monte Carlo which leverages the smooth geometry of the manifold to coherently move between inputs exactly consistent with observations. We validate the method by performing inference experiments in a diverse set of models.
            </div>
          </li>
          </ul>
          <h2 class='sub-heading'>Conference proceedings</h2>
          <ul class="publications-list">
            <li class="publication">
              <h4>
                <small>08/2017</small>
                Continuously tempered Hamiltonian Monte Carlo
              </h4>
              <p>
                <i>Matthew M. Graham</i> and <a href="http://homepages.inf.ed.ac.uk/amos">Amos J. Storkey</a>
              </p>
              <p class='published-in'>
                Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence
              </p>
              <div class="btn-group" role="group">
                <a href="http://auai.org/uai2017/proceedings/papers/289.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-f"></i> Proceedings
                </a>
                <a href="http://auai.org/uai2017/proceedings/supplements/289.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-f"></i> Supplement
                </a>
                <a href="https://arxiv.org/abs/1704.03338" class="btn btn-default">
                  <i class="ai ai-arxiv fa-fw"></i> arXiv
                </a>
                <a href="https://github.com/matt-graham/continuously-tempered-hmc" class="btn btn-default">
                  <i class="fa fa-code fa-fw"></i> Code
                </a>
                <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#cthmc-abs">
                  Abstract
                </button>
              </div>
              <div id="cthmc-abs" class="collapse abstract">
                Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC) method for performing approximate inference in complex probabilistic models of continuous variables. In common with many MCMC methods, however, the standard HMC approach performs poorly in distributions with multiple isolated modes. We present a method for augmenting the Hamiltonian system with an extra continuous temperature control variable which allows the dynamic to bridge between sampling a complex target distribution and a simpler unimodal base distribution. This augmentation both helps improve mixing in multimodal targets and allows the normalisation constant of the target distribution to be estimated. The method is simple to implement within existing HMC code, requiring only a standard leapfrog integrator. We demonstrate experimentally that the method is competitive with annealed importance sampling and simulating tempering methods at sampling from challenging multimodal distributions and estimating their normalising constants.
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>04/2017</small>
                Asymptotically exact inference in differentiable generative models
              </h4>
              <p>
                <i>Matthew M. Graham</i> and <a href="http://homepages.inf.ed.ac.uk/amos">Amos J. Storkey</a>
              </p>
              <p class='published-in'>
                Proceedings of the 20th International Conference on Artificial Intelligence and Statistics
              </p>
              <div class="btn-group" role="group">
                <a href="http://proceedings.mlr.press/v54/graham17a.html" class="btn btn-default">
                  <i class="fa fa-file-o fa-fw"></i> Proceedings
                </a>
                <a href="https://arxiv.org/abs/1605.07826" class="btn btn-default">
                  <i class="ai ai-arxiv fa-fw"></i> arXiv
                </a>
                <a href="files/dgm_poster.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-fw"></i> Poster
                </a>
                <a href="slides/dgm" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
                <a href="https://github.com/matt-graham/differentiable-generative-models" class="btn btn-default">
                  <i class="fa fa-code fa-fw"></i> Code
                </a>
                <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#dgm-abs">
                  Abstract
                </button>
              </div>
              <div id="dgm-abs" class="collapse abstract">
                Many generative models can be expressed as a differentiable function of random inputs drawn from some simple probability density. This framework includes both deep generative architectures such as Variational Autoencoders and a large class of procedurally defined simulator models. We present a method for performing efficient MCMC inference in such models when conditioning on observations of the model output. For some models this offers an asymptotically exact inference method where Approximate Bayesian Computation might otherwise be employed. We use the intuition that inference corresponds to integrating a density across the manifold corresponding to the set of inputs consistent with the observed outputs. This motivates the use of a constrained variant of Hamiltonian Monte Carlo which leverages the smooth geometry of the manifold to coherently move between inputs exactly consistent with observations. We validate the method by performing inference tasks in a diverse set of models.
              </div>
            </li>
            <li class="publication">
              <h4><small>05/2016</small> Pseudo-Marginal Slice Sampling</h4>
              <p>
                <a href="http://homepages.inf.ed.ac.uk/imurray2/">Iain Murray</a> and <i>Matthew M. Graham</i>
              </p>
              <p class='published-in'>
                Proceedings of the 19th International Conference on Artificial Intelligence and Statistics
              </p>
              <div class="btn-group" role="group">
                <a href="http://proceedings.mlr.press/v51/murray16.html" class="btn btn-default">
                  <i class="fa fa-file-o fa-fw"></i> Proceedings
                </a>
                <a href="https://arxiv.org/abs/1510.02958" class="btn btn-default">
                  <i class="ai ai-arxiv fa-fw"></i> arXiv
                </a>
                <a href="files/pm_slice_poster.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-fw"></i> Poster
                </a>
                <a href="https://github.com/matt-graham/auxiliary-pm-mcmc" class="btn btn-default">
                  <i class="fa fa-code fa-fw"></i> Code
                </a>
                <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#pm-slice-abs">
                  Abstract
                </button>
              </div>
              <div id="pm-slice-abs" class="collapse abstract">
                Markov chain Monte Carlo (MCMC) methods asymptotically sample from complex probability distributions.
                The pseudo-marginal MCMC framework only requires an unbiased estimator of the unnormalized probability
                distribution function to construct a Markov chain. However, the resulting chains are harder to tune
                to a target distribution than conventional MCMC, and the types of updates available are limited.
                We describe a general way to clamp and update the random numbers used in a pseudo-marginal method's
                unbiased estimator. In this framework we can use slice sampling and other adaptive methods. We obtain
                more robust Markov chains, which often mix more quickly.
              </div>
            </li>
          </ul>
          <h2 class='sub-heading'>Workshop papers </h2>
          <ul class="publications-list">
            <li class="publication">
              <h4>
                <small>08/2017</small>
                Inference in differentiable generative models
              </h4>
              <p>
                <i>Matthew M. Graham</i> and <a href="http://homepages.inf.ed.ac.uk/amos">Amos J. Storkey</a>
              </p>
              <p class='published-in'>
                ICML 2017 workshop: Implicit generative models
              </p>
              <div class="btn-group" role="group">
                <a href="https://matt-graham.github.io/files/inference-in-differentiable-generative-models-graham-and-storkey.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-fw"></i> Extended abstract
                </a>
                <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#dgm-wk-abs">
                  Abstract
                </button>
              </div>
              <div id="dgm-wk-abs" class="collapse abstract">
                Many generative models can be expressed as a differentiable function of random inputs drawn from a known probability distribution. This framework includes both learnt parametric generative models and a large class of procedurally defined simulator models. We present a method for performing efficient Markov chain Monte Carlo (MCMC) inference in such models when conditioning on observations of the model output. For some models this offers an asymptotically exact inference method where Approximate Bayesian Computation might otherwise be employed. We use the intuition that inference corresponds to integrating a density across the manifold corresponding to the set of inputs consistent with the observed outputs. This motivates the use of a constrained variant of Hamiltonian Monte Carlo which leverages the smooth geometry of the manifold to move between inputs exactly consistent with observations.
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>12/2016</small>  Continuously tempered Hamiltonian Monte Carlo
              </h4>
              <p>
                <i>Matthew M. Graham</i> and <a href="http://homepages.inf.ed.ac.uk/amos">Amos J. Storkey</a>
              </p>
              <p class='published-in'>
                NIPS 2016 workshop: Advances in Approximate Bayesian Inference
              </p>
              <div class="btn-group" role="group">
                <a href="http://approximateinference.org/accepted/GrahamStorkey2016.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-fw"></i> Extended abstract
                </a>
                <a href="files/cthmc/poster.pdf" class="btn btn-default">
                  <i class="fa fa-file-pdf-o fa-fw"></i> Poster
                </a>
                <a href="slides/cthmc/aabi" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
                <button class="btn btn-default btn-abs collapsed" data-toggle="collapse" data-target="#cthmc-wk-abs">
                  Abstract
                </button>
              </div>
              <div id="cthmc-wk-abs" class="collapse abstract">
                Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC) method for performing approximate inference in complex probabilistic models of continuous variables. In common with many MCMC methods however the standard HMC approach performs poorly in distributions with multiple isolated modes. Based on an approach proposed in the statistical physics literature, we present a method for augmenting the Hamiltonian system with an extra continuous temperature control variable which allows the dynamic to bridge between sampling a complex target distribution and a simpler uni-modal base distribution. This augmentation both helps increase mode-hopping in multi-modal targets and allows the normalisation constant of the target distribution to be estimated. The method is simple to implement within existing HMC code, requiring only a standard leapfrog integrator. It produces MCMC samples from the target distribution which can be used to directly estimate expectations without any importance re-weighting.
              </div>
            </li>
          </ul>
        </div> <!-- row Publications -->
      </div>
    </div>
    
    <div class="row" id="talks">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1> Talks </h1>
        </div>
        <div class="row">
          <ul class="publications-list">
              <li class="publication">
                <h4>
                  <small>11/2017</small> Inference in differentiable generative models
                </h4>
                <p class='published-in'>
                  <a href='https://www.stat.nus.edu.sg/index.php/events/academic/seminars/eventdetail/28/-/inference-in-differentiable-generative-models'>Seminar at Department of Statistics and Applied Probability, National University of Singapore.</a>
                </p>
                <div class="btn-group" role="group">
                  <a href="slides/dgm/nus.html" class="btn btn-default">
                    <i class="fa fa-television fa-fw"></i> Slides
                  </a>
                </div>
              </li>
            <li class="publication">
              <h4>
                <small>08/2017</small> Continuously tempered Hamiltonian Monte Carlo
              </h4>
              <p class='published-in'>
                <a href='http://auai.org/uai2017/schedule.php'>33rd Conference on Uncertainty in Artificial Intelligence</a>
              </p>
              <div class="btn-group" role="group">
                <a href="slides/cthmc/uai.html" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>07/2017</small> Inference in implicit generative models
              </h4>
              <p class='published-in'>
                Seminar at School of Mathematics and Statistics, University of Newcastle
              </p>
              <div class="btn-group" role="group">
                <a href="slides/dgm/newcastle.html" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>04/2017</small> Asymptotically exact inference in differentiable generative models
              </h4>
              <p class='published-in'>
                <a href='http://www.aistats.org'>20th International Conference on Artificial Intelligence and Statistics</a>
              </p>
              <div class="btn-group" role="group">
                <a href="slides/dgm/aistats.html" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>02/2017</small> Inference in differentiable generative models
              </h4>
              <p class='published-in'>
                <a href='https://www.birs.ca/events/2017/5-day-workshops/17w5025'>BIRS workshop: Validating and Expanding Approximate Bayesian Computation Methods</a>
              </p>
              <div class="btn-group" role="group">
                <a href="slides/birs" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
                <a href="https://www.birs.ca/events/2017/5-day-workshops/17w5025/videos/watch/201702201643-Graham.html" class="btn btn-default">
                  <i class="fa fa-file-video-o fa-fw"></i> Video
                </a>  
              </div>
            </li>
            <li class="publication">
              <h4>
                <small>12/2016</small> Continuously tempered Hamiltonian Monte Carlo
              </h4>
              <p class='published-in'>
                <a href='http://approximateinference.org/'>NIPS 2016 workshop: Advances in Approximate Bayesian Inference</a>
              </p>
              <div class="btn-group" role="group">
                <a href="slides/cthmc/aabi.html" class="btn btn-default">
                  <i class="fa fa-television fa-fw"></i> Slides
                </a>
                <a href="https://www.youtube.com/watch?v=4fi-lZ8mn5Q&index=11&list=PL8Yb49e5zFuztzY4wZRp_XIj6PREg3pw8" class="btn btn-default">
                  <i class="fa fa-youtube fa-fw"></i> Video
                </a>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </div>
    
    <div class="row" id="projects">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Projects</h1>
        </div>

        <div class="row" id="phd-project">
          <h3>
            <span class="text-muted">PhD project:</span>
            Auxiliary variable MCMC methods
            <small>(Supervisor: <a href="http://homepages.inf.ed.ac.uk/amos">Amos Storkey</a>)</small>
          </h3>
        </div>
        <div class="row">
          <div class="col-md-3">
            <img src="images/mcmc_visualisation_cropped.png" width="256" class="img-thumbnail center-block vertical-buffer"/>
          </div>
          <div class="col-md-9 vertical-buffer">
            <p>
              My PhD project was focussed on developments to <em>Markov Chain Monte Carlo</em> (MCMC) methods. I specifically considered methods which augment the system state space with additional auxiliary variables. In some cases this allows the robustness or efficiency of sampling methods to be improved, for example by making it easier for the sampler to coherently explore the target distribution or to increase movement between modes in multimodal target distributions. In other settings redefining the state space of the problem can allow us to perform inference in settings where we do not have an explicit form for the distribution on the variables of interest.
            </p>
            <div class="btn-group" role="group">
              <a href="files/phd_thesis.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Thesis
              </a>
            </div>
          </div>
        </div>
        
        <div class="row" id="msc-project">
          <h3>
            <span class="text-muted">MSc by Research project:</span> Insect olfactory landmark navigation
            <small>(Supervisor: <a href="http://homepages.inf.ed.ac.uk/bwebb">Barbara Webb</a>)</small>
          </h3>
        </div>
        <div class="row">
          <div class="col-md-3">
            <img src="images/msc_project_ant.jpg" width="256" class="img-thumbnail center-block"/>
          </div>
          <div class="col-md-9">
            <p>This project was motivated by the work of <a href="http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-21299/Steck/Dissertation.pdf">Kathrin Steck and colleagues</a> who discovered that <em>Cataglyphis fortis</em>, a Saharan desert ant species, are able to use odour sources in their environment as 'landmarks' to help when navigating back to their nest. A field study was conducted attempting to see if the previous results could be observed when ants were subjected to a more complex navigation task and an information-theoretic analysis used to try to establish how much positional information is available from local olfactory sensation of remote odour sources.</p>
            <div class="btn-group" role="group">
              <a href="files/msc_project_report.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Report
              </a>
              <a href="files/msc_project_poster.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Poster
              </a>
            </div>
          </div>
        </div>
        <div class="row" id="meng-project">
          <h3>
            <span class="text-muted">MEng project:</span> Measuring tissue stiffness with ultrasound
            <small>(Supervisor: <a href="http://mi.eng.cam.ac.uk/~gmt11/">Graham Treece</a>)</small>
          </h3>
        </div>
        <div class="row">
          <div class="col-md-3">
            <img src="images/meng_project_overview.png" width="256" class="img-thumbnail center-block"/>
          </div>
          <div class="col-md-9">
            <p>This project was based around the technique of ultrasound elastography. In particular I was trying to develop a technique for estimating absolute stiffness at a small set of points in an ultrasound image plane by tracking the propagation of shear waves produced by a surface tap using standard ultrasound imaging hardware.</p>
            <div class="btn-group" role="group">
              <a href="files/meng_project_abstract.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Abstract
              </a>
              <a href="files/meng_project_report.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Report
              </a>
              <a href="files/meng_project_presentation.pdf" class="btn btn-default">
                <i class="fa fa-file-pdf-o fa-fw"></i> Presentation
              </a>
            </div> <!-- btn-group -->
          </div> <!-- col -->
        </div>
      </div>
    </div> <!--./research -->

    <div class="row" id="code">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Code</h1>
        </div>
        <div class="row">
          <div class="col-xs-12">
            <p class="space-bottom">
              Most of my code can be found on <a href="https://github.com/matt-graham">my Github profile</a>. Below are a selection of the possibly  more generally useful repositories.
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-6">
            <div class="github-card panel panel-default"
              data-repo="matt-graham/auxiliary-pm-mcmc">
            </div>
            <div class="github-card panel panel-default"
              data-repo="matt-graham/hmc">
            </div>
            <div class="github-card panel panel-default"
              data-repo="matt-graham/thermodynamic-monte-carlo">
            </div>
          </div>
          <div class="col-sm-6">
            <div class="github-card panel panel-default"
              data-repo="matt-graham/boltzmann-machine-tools">
            </div>
            <div class="github-card panel panel-default"
              data-repo="matt-graham/reversible-rng">
            </div>
            <div class="github-card panel panel-default"
              data-repo="InsectRobotics/pompy">
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="row" id="teaching">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1>Teaching</h1>
        </div>
        <div class="row">
          <h2 class="sub-heading">University of Edinburgh, School of Informatics</h2>
          <p class="pad-sides">
            I was the teaching assistant for the coursework-based <a href='http://www.inf.ed.ac.uk/teaching/courses/mlp/'>Machine Learning Practical</a> in the 2016-2017 academic year. The Jupyter notebooks and Python framework I helped co-develop for the course lab sessions are available at <a href="https://github.com/CSTR-Edinburgh/mlpractical/tree/mlp2016-7/master">the course Github repository</a>. I have also previously tutored for <a href="http://www.inf.ed.ac.uk/teaching/courses/mlpr/2016/">Machine Learning and Pattern Recognition</a>, <a href="http://www.inf.ed.ac.uk/teaching/courses/it/">Information Theory</a> and <a href="http://www.inf.ed.ac.uk/teaching/courses/pmr/">Probabilistic Modelling and Reasoning (PMR)</a>. There a couple of Jupyter notebooks with notes on PMR topics I made when tutoring on Github <a href="https://github.com/matt-graham/pmr-notebooks">here</a>.
          </p>
          <p class="pad-sides">
            I did a short tutorial on Hamiltonian Monte Carlo for the Institute for Adaptive and Neural Computation <a href="https://wiki.inf.ed.ac.uk/ANC/PIGlets">PIGlets</a> discussion group. The slides are available <a href="slides/hmc-tutorial">here</a> and an associated Jupyter notebook going through an example implementation is available <a href="https://github.com/ANC-PIGlets/gradient-based-mcmc/blob/master/Hamiltonian%20Monte%20Carlo.ipynb">on Github</a>.
          </p>
        </div>
      </div>
    </div>

    <div class="row" id="misc">
      <div class="col-xs-12">
        <div class="row section-header">
          <h1><small>Non-work</small> interests</h1>
        </div>
        <div class="row text-center">
          <div class="pad-sides space-bottom">
            <img src="images/mountain_dawn.jpg" class="img-thumbnail center-block" />
            <h6>Dawn sky over the Cairngorm plateau</h6>
          </div>
        </div>
        <div class="row">
          <p class="pad-sides">
            In my spare time I'm a keen hillwalker and mountaineer. I walked extensively with the
            <a href="http://www.cuhwc.org.uk">Cambridge University Hillwalking Club</a> during my undergraduate studies. In the summer of 2012 I helped organise and took part in an
            <a href="http://www.catse.org.uk">expedition to the Tien Shan range</a> in Kyrgyzstan
            with seven other CUHWC members. During my PhD in Edinburgh I was a member of
            <a href="http://euhwc.eusu.ed.ac.uk">Edinburgh University Hillwalking Club</a> and also began climbing in and outdoors more regularly (though still sadly not all that often!).
          </p>
        </div>
      </div>
    </div>

    <div class="row" id="footer">
      <div class="col-xs-12">
        <hr />
        <p class="text-center">
          Built using <a href="http://getbootstrap.com">Bootstrap</a>. Icons from <a href="http://fortawesome.github.io/Font-Awesome/">FontAwesome</a> and <a href="https://jpswalsh.github.io/academicons/">Academicons</a>.
        </p>
      </div>
    </div><!--./footer-->

  </div><!-- /.container -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
  <script src="js/bootstrap.js"></script>
  <script src="js/plugins.js"></script>

  <script>
  $('#mainNav').onePageNav({
    currentClass: 'active',
    changeHash: true,
    scrollSpeed: 1200
  });
  </script>

  <script>
    $('.github-card').each(function( i, div ) {
      var request = new XMLHttpRequest();
      request.onload = function () {
        var repo = JSON.parse(this.responseText);
        div.innerHTML = `<div class="panel-heading"><i class="fa fa-github fa-fw"></i> <a href="${repo.html_url}">${repo.name}</a> <small>(${repo.language})</small></div><div class="panel-body">${repo.description}</div>`;
      };
      request.open('get', 'https://api.github.com/repos/'.concat( div.dataset.repo), true);
      request.send();
    });
  </script>


</body>

</html>
